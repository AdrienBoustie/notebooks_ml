{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the clean trees data from saved pickle into the `trees` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List first 5 elements of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `train_test_split` from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we want to build a machine learning model that helps us predict the plantation year for different trees based on their characteristics.\n",
    "\n",
    "For this you have to first remove the column `ANNEEDEPLANTATION` from the dataframe and save the result in the variable `year`. Hint: use `pop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the `trees` and the `year` data into train and test partitions. Use seed=800.\n",
    "\n",
    "You must save the result in 4 variables: X_train (instances in the train set), X_test (instances in the test set), y_train (labels corresponding to the instances in the train set), y_test (labels corresponding to the instances in the test set).\n",
    "\n",
    "For clarifications, read the `train_test_split` documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many instanes are there in the train set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many instances are there in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display basic statistics on the train data (count, mean, std, etc.) - do it in one line! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display basic statistics on the test data (count, mean, std, etc.) - do it in one line! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the distribution of the labels in the train set using a histogram with 50 bins. Do not call matplotlib explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the distribution of the data in different columns of the train set using a histogram default number of bins. Do not call matplotlib explicitly and do it in one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the number of missing values for each column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a first naive model\n",
    "\n",
    "We will consider we can determine the plantation year of trees in the test set based solely on the median value of the plantation year for the trees in the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the median value of plantation year for trees in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the shape of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable `y_test_pred`. This will serve to store the predictions of your machine learning model on the test set.\n",
    "\n",
    "It has to be an array of the same length as the number of test examples (in X_test).\n",
    "\n",
    "Initialize this variable to have the median value from the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the contents of `y_test_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import from the scikit-learn library the necessary function to compute the mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to compute the error on the test set. Print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data and build new models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make a processing pipeline using only numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the following code and write what it does the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `Pipeline` consisting of 3 steps: \n",
    "- selecting only the numerical attributes from the dataframe that could make sense for the prediction (longitude and latitude), \n",
    "- replacing missing values with the median of each column, \n",
    "- normalizing the data (removing the mean and scaling to unit variance).\n",
    "\n",
    "For this, get help from the scikit learn documentation related to the corresponding functions.\n",
    "Your code has to be one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['LONGITUDE', 'LATITUDE']\n",
    "\n",
    "# code here\n",
    "num_pipeline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the longitude and latitude of the first elements in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the documentation for `fit_transform()` if you are unfamiliar with the method.\n",
    "\n",
    "Apply the `fit_transform()` to the train data and save the result in `X_trainT`. Inspect its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `transform` to the test data. Save the result in a variable `X_testT` and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the above output represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above process by selectively commenting parts of the processing in the `Pipeline` and changing the missing values handling strategy. Observe the results and write down your observations below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are `Pipeline`s useful for? Answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Start modelling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start modelling. We will start with a Linear Regression model.\n",
    "\n",
    "#### Linear Regression\n",
    "\n",
    "Import from scikit learn what is necessary to 1)perform linear regression and to 2)compute the cross validation score (`cross_val_score`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the documentation pages of the above two functions to understand their usage.\n",
    "\n",
    "To better understand how cross validation works, read the documentation page from scikit learn `3.1. Cross-validation: evaluating estimator performance` up until Section `3.1.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a linear regression instance and save it in the `lin_reg` variable below. Build a model on the training set, calling the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 10-fold cross validation with the metric to apply to the estimator (i.e. the scoring function) set to mean squared error.\n",
    "\n",
    "Print the resulting scores of the cross validation and the descriptive statistics (mean, std, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees\n",
    "\n",
    "Import from scikit learn what is necessary to build a Decision Trees model for a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of a `DecisionTreeRegressor` with `random_state=43` and save it in the `tree_reg` variable below. Leave all the other parameters to their default values. Build a model on the training set, calling the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 10-fold cross validation with the metric to apply to the estimator (i.e. the scoring function) set to mean squared error.\n",
    "\n",
    "Print the resulting scores of the cross validation and the descriptive statistics (mean, std, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the results obtained using the `DecisionTreeRegressor` in comparison to the results obtained using `LinearRegression` and in comparison to the Naive Model from the beginning of this notebook? \n",
    "\n",
    "Write down below the mean squared error value for each of them and your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Alter the hyper-parameters of the model\n",
    "\n",
    "Previously you called the `DecisionTreeRegressor`function with default parameters.\n",
    "\n",
    "In the following we will explore running different Decision Tree models with different parameters.\n",
    "\n",
    "To begin with, inspect the scikit learn page of `DecisionTreeRegressor` to understand which are the possible different hyper-parameters that you can adjust. Call a function to get the parameters of the `DecisionTreeRegressor`, save the result in a variable and display its contents below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 10 new instances of a `DecisionTreeRegressor` and save them in 10 different variables, while keeping `random_state=43`. \n",
    "\n",
    "For each of them alter the default parameters by inputing different values for each of the following: `min_impurity_decrease`,  `max_depth`, `max_features`. Then, for each of them build a model on the training set, calling the `fit()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 10-fold cross validation with the metric to apply to the estimator (i.e. the scoring function) set to mean squared error.\n",
    "\n",
    "Print the resulting scores of the cross validation and the descriptive statistics (mean, std, etc.) for all 10 models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is the performance different for different models? Answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the models on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now you have only investigated the performance (in terms of mean squared error) of the models on the train set. However, in practice we are interested to know how well a model generalizes on unseen data.\n",
    "\n",
    "Evaluate each of the above models on the test set. Record below the following: \n",
    "* model name & parameters\n",
    "* model score on the train set\n",
    "* model score on the test set\n",
    "\n",
    "Rememeber: you had to apply the exact same pre-processing steps for the train and test set: you did this in Section `Make a processing pipeline using only numerical data` and saved the results in `X_trainT` and `X_testT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the models compare to each other? Can you observe any overfitting? For which model? Answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Grid search for the best parameters\n",
    "\n",
    "Previously, you tried several models with different values for different hyper-parameters, by choosing these values manually and evaluating each model individually. However, doing so exhaustically is impossible in practice in a given limited amount of time. \n",
    "\n",
    "In the following you will see how you can speed up the process and use a grid search over a set of parameters to find the best ones that fit the train data.\n",
    "\n",
    "For this, read the documentation for the `GridSearchCV` function in scikit learn. Make the necessary import below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from scikit learn the documentation page `3.2. Tuning the hyper-parameters of an estimator` to understand the usage of `GridSearchCV`.\n",
    "\n",
    "Apply a grid search strategy with 10-fold cross validation to select the best parameters for fitting the train set using a `DecisionTreeRegressor`. Use the `r2` scoring function. Make sure your grid search is done over at least 200 models (it will take a bit of time, it's normal). HINT: you can use ranges of values for setting certain hyper-parameters, instead of defining them manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the obtained model on both the train set and the test set. NOTE: do not forget to use the transformed version of these sets obtained after having applied the processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is the performance of the new model compared to all previous performances? Answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to print the best values for each the parameters on which you did the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! You are now able to run a full machine learning pipeline from data preprocessing to model building and evaluation. Now it is time to repeat the process with different / more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "1. Repeat the above process to create a pipeline only for categorical variables.\n",
    "2. Build models with the resulting transformed data.\n",
    "3. Compare the performance of the new models to the previous ones built on top of only numerical variables.\n",
    "\n",
    "4. Is it worth combining both catagorical and numerical variables? If so, try to combine both pipelines, build new models and compare the performance to the previous models.\n",
    "\n",
    "For each of the above points:\n",
    "* write the code needed to solve the task;\n",
    "* run the code and print the results;\n",
    "* write an explanation of what you did in a markdown cell below the code.\n",
    "\n",
    "Add as many cells below as necessary to solve all the required points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
